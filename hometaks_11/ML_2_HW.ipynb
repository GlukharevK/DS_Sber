{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression, RidgeCV, LassoCV, LogisticRegression\n",
    "from sklearn.metrics import r2_score, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset.data)\n",
    "X.columns = dataset.feature_names\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso и параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для линейной модели: 0.6687594935356318\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred = linear_model.predict(X_test)\n",
    "r2_linear_model = r2_score(y_test, y_pred)\n",
    "print(f'R2 метрика для линейной модели: {r2_linear_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации(используйте GridSearchCV, RidgeCV, LassoCV) в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по лучшим моделям и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def degree_10():\n",
    "    for i in range(10):\n",
    "        yield 10e-5 * 10 ** i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge через GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для Ridge модели: 0.6687594145292219\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'alpha' : [i for i in degree_10()]}\n",
    "ridge_model = Ridge()\n",
    "grid_ridge_model = GridSearchCV(ridge_model, parametrs, scoring='r2')\n",
    "grid_ridge_model.fit(X_train, y_train)\n",
    "y_pred_ridge = grid_ridge_model.predict(X_test)\n",
    "r2_ridge_model = r2_score(y_test, y_pred_ridge)\n",
    "print(f'R2 метрика для Ridge модели: {r2_ridge_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для RidgeCV модели: 0.6687510090373743\n"
     ]
    }
   ],
   "source": [
    "ridgecv_model = RidgeCV(alphas=[i for i in degree_10()], scoring='r2')\n",
    "ridgecv_model.fit(X_train, y_train)\n",
    "y_pred_ridgecv = ridgecv_model.predict(X_test)\n",
    "r2_ridgecv_model = r2_score(y_test, y_pred_ridgecv)\n",
    "print(f'R2 метрика для RidgeCV модели: {r2_ridgecv_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge через GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для Lasso модели: 0.6687631534779594\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso()\n",
    "grid_lasso_model = GridSearchCV(lasso_model, parametrs, scoring='r2')\n",
    "grid_lasso_model.fit(X_train, y_train)\n",
    "y_pred_lasso = grid_lasso_model.predict(X_test)\n",
    "r2_lasso_model = r2_score(y_test, y_pred_lasso)\n",
    "print(f'R2 метрика для Lasso модели: {r2_lasso_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для RidgeCV модели: 0.6687631534779594\n"
     ]
    }
   ],
   "source": [
    "lassocv_model = LassoCV(alphas=[i for i in degree_10()])\n",
    "lassocv_model.fit(X_train, y_train)\n",
    "y_pred_lassocv = lassocv_model.predict(X_test)\n",
    "r2_lassocv_model = r2_score(y_test, y_pred_lassocv)\n",
    "print(f'R2 метрика для RidgeCV модели: {r2_lassocv_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат одинаковый для всех моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки(используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge + StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для Lasso+StandardScaler модели: 0.6684624359643561\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'ridge__alpha' : [i for i in degree_10()]}\n",
    "pipe_ridge_ss = make_pipeline(StandardScaler(), Ridge())\n",
    "grid_ridge_ss_model = GridSearchCV(pipe_ridge_ss, parametrs, scoring='r2')\n",
    "grid_ridge_ss_model.fit(X_train, y_train)\n",
    "y_pred_ridge_ss = grid_ridge_ss_model.best_estimator_.predict(X_test)\n",
    "r2_grid_ridge_ss_model = r2_score(y_test, y_pred_ridge_ss)\n",
    "print(f'R2 метрика для Lasso+StandardScaler модели: {r2_grid_ridge_ss_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge__alpha': 1.0}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ridge_ss_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge + MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для Ridge+MinMaxScaler модели: 0.6700309977617649\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'ridge__alpha' : [i for i in degree_10()]}\n",
    "pipe_ridge_ss = make_pipeline(MinMaxScaler(), Ridge())\n",
    "grid_ridge_ss_model = GridSearchCV(pipe_ridge_ss, parametrs, scoring='r2')\n",
    "grid_ridge_ss_model.fit(X_train, y_train)\n",
    "y_pred_ridge_ss = grid_ridge_ss_model.best_estimator_.predict(X_test)\n",
    "r2_grid_ridge_ss_model = r2_score(y_test, y_pred_ridge_ss)\n",
    "print(f'R2 метрика для Ridge+MinMaxScaler модели: {r2_grid_ridge_ss_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge__alpha': 0.1}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ridge_ss_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso + StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для Lasso+MinMaxScaler модели: 0.6687548978932025\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'lasso__alpha' : [i for i in degree_10()]}\n",
    "pipe_lasso_ss = make_pipeline(StandardScaler(), Lasso())\n",
    "grid_lasso_ss_model = GridSearchCV(pipe_lasso_ss, parametrs, scoring='r2')\n",
    "grid_lasso_ss_model.fit(X_train, y_train)\n",
    "y_pred_lasso_ss = grid_lasso_ss_model.best_estimator_.predict(X_test)\n",
    "r2_grid_lasso_ss_model = r2_score(y_test, y_pred_lasso_ss)\n",
    "print(f'R2 метрика для Lasso+MinMaxScaler модели: {r2_grid_lasso_ss_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso__alpha': 0.0001}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lasso_ss_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso + MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для Lasso+MinMaxScaler модели: 0.6687693392484069\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'lasso__alpha' : [i for i in degree_10()]}\n",
    "pipe_lasso_mm = make_pipeline(MinMaxScaler(), Lasso())\n",
    "grid_lasso_mm_model = GridSearchCV(pipe_lasso_mm, parametrs, scoring='r2')\n",
    "grid_lasso_mm_model.fit(X_train, y_train)\n",
    "y_pred_lasso_mm = grid_lasso_mm_model.best_estimator_.predict(X_test)\n",
    "r2_grid_lasso_mm_model = r2_score(y_test, y_pred_lasso_mm)\n",
    "print(f'R2 метрика для Lasso+MinMaxScaler модели: {r2_grid_lasso_mm_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso__alpha': 0.0001}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lasso_mm_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат у RidgeCV + MinMaxScaler = 0.6700309977617649"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитано в п.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для Lasso+StandardScaler+PolynomialFeatures модели: 0.8180465877243648\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'ridge__alpha' : [i for i in degree_10()]}\n",
    "pipe_ridge_ss = make_pipeline(StandardScaler(), PolynomialFeatures(2), Ridge())\n",
    "grid_ridge_ss_model = GridSearchCV(pipe_ridge_ss, parametrs, scoring='r2')\n",
    "grid_ridge_ss_model.fit(X_train, y_train)\n",
    "y_pred_ridge_ss = grid_ridge_ss_model.best_estimator_.predict(X_test)\n",
    "r2_grid_ridge_ss_model = r2_score(y_test, y_pred_ridge_ss)\n",
    "print(f'R2 метрика для Lasso+StandardScaler+PolynomialFeatures модели: {r2_grid_ridge_ss_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для Ridge+MinMaxScaler+PolynomialFeatures модели: 0.8500630422288795\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'ridge__alpha' : [i for i in degree_10()]}\n",
    "pipe_ridge_ss = make_pipeline(MinMaxScaler(), PolynomialFeatures(2), Ridge())\n",
    "grid_ridge_ss_model = GridSearchCV(pipe_ridge_ss, parametrs, scoring='r2')\n",
    "grid_ridge_ss_model.fit(X_train, y_train)\n",
    "y_pred_ridge_ss = grid_ridge_ss_model.best_estimator_.predict(X_test)\n",
    "r2_grid_ridge_ss_model = r2_score(y_test, y_pred_ridge_ss)\n",
    "print(f'R2 метрика для Ridge+MinMaxScaler+PolynomialFeatures модели: {r2_grid_ridge_ss_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для Lasso+MinMaxScaler+PolynomialFeatures модели: 0.8122168137984359\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'lasso__alpha' : [i for i in degree_10()]}\n",
    "pipe_lasso_ss = make_pipeline(StandardScaler(), PolynomialFeatures(2), Lasso())\n",
    "grid_lasso_ss_model = GridSearchCV(pipe_lasso_ss, parametrs, scoring='r2')\n",
    "grid_lasso_ss_model.fit(X_train, y_train)\n",
    "y_pred_lasso_ss = grid_lasso_ss_model.best_estimator_.predict(X_test)\n",
    "r2_grid_lasso_ss_model = r2_score(y_test, y_pred_lasso_ss)\n",
    "print(f'R2 метрика для Lasso+MinMaxScaler+PolynomialFeatures модели: {r2_grid_lasso_ss_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 метрика для Lasso+MinMaxScaler+PolynomialFeatures модели: 0.8390581680518306\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'lasso__alpha' : [i for i in degree_10()]}\n",
    "pipe_lasso_mm = make_pipeline(MinMaxScaler(), PolynomialFeatures(2), Lasso())\n",
    "grid_lasso_mm_model = GridSearchCV(pipe_lasso_mm, parametrs, scoring='r2')\n",
    "grid_lasso_mm_model.fit(X_train, y_train)\n",
    "y_pred_lasso_mm = grid_lasso_mm_model.best_estimator_.predict(X_test)\n",
    "r2_grid_lasso_mm_model = r2_score(y_test, y_pred_lasso_mm)\n",
    "print(f'R2 метрика для Lasso+MinMaxScaler+PolynomialFeatures модели: {r2_grid_lasso_mm_model}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат значительно улучшился, лучший результат у Lasso+StandardScaler+PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2. Напишите как изменился R2 по сравнению с предыдущими экспериментами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:16<00:16, 16.88s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:42<00:00, 21.43s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:42<00:42, 42.87s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:03<00:03,  3.51s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.44s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:49<00:00, 24.88s/it]\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for estimator in tqdm([Lasso(), Ridge()]):\n",
    "    for scaler in tqdm([MinMaxScaler(), StandardScaler()]):\n",
    "        parametrs = {f'{str.lower(str(estimator))[:-2]}__alpha' : [i for i in degree_10()],\n",
    "                     'polynomialfeatures__degree' : [2,3,4]}\n",
    "        main_pipe = make_pipeline(scaler, PolynomialFeatures(), estimator)\n",
    "        main_model = GridSearchCV(main_pipe, parametrs, scoring='r2')\n",
    "        main_model.fit(X_train, y_train)\n",
    "        y_pred_main = main_model.predict(X_test)\n",
    "        res[f'{estimator}, {scaler}, {main_model.best_params_}'] = r2_score(y_test, y_pred_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Lasso(), MinMaxScaler(), {'lasso__alpha': 0.001, 'polynomialfeatures__degree': 3}\": 0.8449734005131516,\n",
       " \"Lasso(), StandardScaler(), {'lasso__alpha': 0.1, 'polynomialfeatures__degree': 2}\": 0.8122168137984359,\n",
       " \"Ridge(), MinMaxScaler(), {'polynomialfeatures__degree': 3, 'ridge__alpha': 0.1}\": 0.8588479918651217,\n",
       " \"Ridge(), StandardScaler(), {'polynomialfeatures__degree': 2, 'ridge__alpha': 10.0}\": 0.8180465877243648}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат Ridge(), MinMaxScaler(), {'polynomialfeatures__degree': 3, 'ridge__alpha': 0.1}\": 0.8588479918651217\n",
    "\n",
    "R2 мало видоизменялся до введения полинома"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/adult-all.csv'\n",
    "data = pd.read_csv('adult-all.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1       2          3   4                   5   \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "3  53           Private  234721       11th   7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  6              7      8       9     10  11  12  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n",
       "1    Exec-managerial        Husband  White    Male     0   0  13   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n",
       "3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n",
       "4     Prof-specialty           Wife  Black  Female     0   0  40   \n",
       "\n",
       "              13     14  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Разделите выборку на признаки и целевую переменную(колонка со зачениями {<=50K,>50K}). Замените целевую переменную на числовые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1].apply(lambda x: 0 if x =='>50K' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    37155\n",
       "0    11687\n",
       "Name: 14, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Выясните, присутствуют ли в данных пропуски. Заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Выберите колонки с числовыми и категориальными переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [1,3,5,6,7,8,9,13]\n",
    "numeric_features = [0,2,4,10,11,12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Создайте пайплайн по обработке колонок(используйте OneHotEncoder,MinMaxScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "numeric_transformer = MinMaxScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8491145460128979"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8491145460128979"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y_test).sum() / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8491145460128979"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((clf.predict_proba(X_test)[:,1] > 0.5) == y_test).sum() / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9039113428943938"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Посчитайте cross_val_score по алгоритмам LogisticRegression, SVC, LinearSVC по метрикам accuracy и f1_score.\n",
    "Напишите удалось ли превзойти предыдущий результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████                                                        | 1/3 [00:06<00:13,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() : accuracy - 0.8511732716999377, f1 - 0.905011719035063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [14:55<08:45, 525.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC() : accuracy - 0.839994419828589, f1 - 0.8986477856490989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [15:08<00:00, 302.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC() : accuracy - 0.8529135478362626, f1 - 0.9063223083526415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator in tqdm([LogisticRegression(), SVC(), LinearSVC()]):\n",
    "    clf = Pipeline(\n",
    "        steps=[(\"preprocessor\", preprocessor), (\"classifier\", estimator)]\n",
    "    )\n",
    "    acc = cross_val_score(clf, X, y, scoring='accuracy').mean()\n",
    "    f1 = cross_val_score(clf, X, y, scoring='f1').mean()\n",
    "    print(f'{estimator} : accuracy - {acc}, f1 - {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат у LinearSVC() : accuracy - 0.8529135478362626, f1 - 0.9063223083526415"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1     2799\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "5        0\n",
       "6     2809\n",
       "7        0\n",
       "8        0\n",
       "9        0\n",
       "10       0\n",
       "11       0\n",
       "12       0\n",
       "13     857\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X == '?').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y == '?').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1       2          3   4                   5   \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "3  53           Private  234721       11th   7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  6              7      8       9     10 11  12             13  \n",
       "0       Adm-clerical  Not-in-family  White    Male  2174  0  40  United-States  \n",
       "1    Exec-managerial        Husband  White    Male     0  0  13  United-States  \n",
       "2  Handlers-cleaners  Not-in-family  White    Male     0  0  40  United-States  \n",
       "3  Handlers-cleaners        Husband  Black    Male     0  0  40  United-States  \n",
       "4     Prof-specialty           Wife  Black  Female     0  0  40           Cuba  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_columns = X.columns\n",
    "imp_mean = SimpleImputer(missing_values='?', strategy='most_frequent')\n",
    "new_data = pd.DataFrame(imp_mean.fit_transform(X), columns=data_columns)\n",
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score на новых данных. Напишите удалось ли улучшить результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████                                                        | 1/3 [00:05<00:11,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() : accuracy - 0.8505999501674596, f1 - 0.9047295620398798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [04:07<02:24, 144.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC() : accuracy - 0.8395848963639935, f1 - 0.8985494397611463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [04:12<00:00, 84.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC() : accuracy - 0.8508251523375897, f1 - 0.905141981677368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator in tqdm([LogisticRegression(), SVC(), LinearSVC()]):\n",
    "    clf = Pipeline(\n",
    "        steps=[(\"preprocessor\", preprocessor), (\"classifier\", estimator)]\n",
    "    )\n",
    "    acc = cross_val_score(clf, new_data, y, scoring='accuracy', n_jobs=-1).mean()\n",
    "    f1 = cross_val_score(clf, new_data, y, scoring='f1', n_jobs=-1).mean()\n",
    "    print(f'{estimator} : accuracy - {acc}, f1 - {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат не улучшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Посчитайте cross_val_score, если просто удалить значения '?'. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_droped_na = data.replace('?', np.NaN).dropna()\n",
    "X_drop_na = data_droped_na.iloc[:,:-1]\n",
    "y_drop_na = data_droped_na.iloc[:,-1].apply(lambda x: 0 if x =='>50K' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████                                                        | 1/3 [00:05<00:11,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() : accuracy - 0.8468445746108516, f1 - 0.90114932100128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████▎                           | 2/3 [03:27<02:00, 120.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC() : accuracy - 0.8356995943179577, f1 - 0.8946665218391704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [03:32<00:00, 70.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC() : accuracy - 0.8485030154158197, f1 - 0.9024033119235104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator in tqdm([LogisticRegression(), SVC(), LinearSVC()]):\n",
    "    clf = Pipeline(\n",
    "        steps=[(\"preprocessor\", preprocessor), (\"classifier\", estimator)]\n",
    "    )\n",
    "    acc = cross_val_score(clf, X_drop_na, y_drop_na, scoring='accuracy', n_jobs=-1).mean()\n",
    "    f1 = cross_val_score(clf, X_drop_na, y_drop_na, scoring='f1', n_jobs=-1).mean()\n",
    "    print(f'{estimator} : accuracy - {acc}, f1 - {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат не улучшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 17. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier. Напишите как изменился результат и какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████                                          | 1/2 [01:18<01:18, 78.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier() : accuracy - 0.8530773228490498, f1 - 0.9049041758416918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:31<00:00, 45.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier() : accuracy - 0.8675731196536806, f1 - 0.9160399106672337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator in tqdm([RandomForestClassifier(), GradientBoostingClassifier()]):\n",
    "    clf = Pipeline(\n",
    "        steps=[(\"preprocessor\", preprocessor), (\"classifier\", estimator)]\n",
    "    )\n",
    "    acc = cross_val_score(clf, X, y, scoring='accuracy', n_jobs=-1).mean()\n",
    "    f1 = cross_val_score(clf, X, y, scoring='f1', n_jobs=-1).mean()\n",
    "    print(f'{estimator} : accuracy - {acc}, f1 - {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат улучшился, решающие деревья лучше решают данную задачу, особенно в ансамбле."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(), MinMaxScaler(), OneHotEncoder(handle_unknown='ignore'), imputer - most_frequent : accuracy - 0.8519922159291594, f1 - 0.9044331346251274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [02:42<02:42, 162.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(), StandardScaler(), OneHotEncoder(handle_unknown='ignore'), imputer - most_frequent : accuracy - 0.8519511652841574, f1 - 0.9047362806564907\n",
      "GradientBoostingClassifier(), MinMaxScaler(), OneHotEncoder(handle_unknown='ignore'), imputer - most_frequent : accuracy - 0.8663855852334714, f1 - 0.9153954075870411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [03:14<00:00, 97.46s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(), StandardScaler(), OneHotEncoder(handle_unknown='ignore'), imputer - most_frequent : accuracy - 0.8663855852334714, f1 - 0.9153954075870411\n",
      "RandomForestClassifier(), MinMaxScaler(), OneHotEncoder(handle_unknown='ignore'), NaN dropped : accuracy - 0.8481491676709088, f1 - 0.9006406014395234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [02:27<02:27, 147.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(), StandardScaler(), OneHotEncoder(handle_unknown='ignore'), NaN dropped : accuracy - 0.8483260512025357, f1 - 0.9015875940336521\n",
      "GradientBoostingClassifier(), MinMaxScaler(), OneHotEncoder(handle_unknown='ignore'), NaN dropped : accuracy - 0.8629208373582479, f1 - 0.9122241531705388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [02:54<00:00, 87.45s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(), StandardScaler(), OneHotEncoder(handle_unknown='ignore'), NaN dropped : accuracy - 0.8629208373582479, f1 - 0.9122523878003121\n",
      "RandomForestClassifier(), MinMaxScaler(), OneHotEncoder(handle_unknown='ignore'), no change data : accuracy - 0.8520125987292536, f1 - 0.9048407761956225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [02:48<02:48, 168.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(), StandardScaler(), OneHotEncoder(handle_unknown='ignore'), no change data : accuracy - 0.852974945650757, f1 - 0.9047524353566881\n",
      "GradientBoostingClassifier(), MinMaxScaler(), OneHotEncoder(handle_unknown='ignore'), no change data : accuracy - 0.8675935946741558, f1 - 0.9160258070962349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [03:15<00:00, 97.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(), StandardScaler(), OneHotEncoder(handle_unknown='ignore'), no change data : accuracy - 0.8675935946741558, f1 - 0.9160258070962349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0,1,2]:\n",
    "    if i == 0:\n",
    "        data_columns = X.columns\n",
    "        imp_mean = SimpleImputer(missing_values='?', strategy='most_frequent')\n",
    "        new_data = pd.DataFrame(imp_mean.fit_transform(X), columns=data_columns)\n",
    "        for estimator in tqdm([RandomForestClassifier(), GradientBoostingClassifier()]):\n",
    "            for numeric_scaler in [MinMaxScaler(), StandardScaler()]:\n",
    "                preprocessor = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        (\"num\", numeric_scaler, numeric_features),\n",
    "                        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "                    ]\n",
    "                )\n",
    "                clf = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor), (\"classifier\", estimator)]\n",
    "                )\n",
    "                acc = cross_val_score(clf, new_data, y, scoring='accuracy', n_jobs=-1).mean()\n",
    "                f1 = cross_val_score(clf, new_data, y, scoring='f1', n_jobs=-1).mean()\n",
    "                test_for_res = f'{estimator}, {numeric_scaler}, {categorical_transformer}, imputer - most_frequent : accuracy - {acc}, f1 - {f1}'\n",
    "                print(test_for_res)\n",
    "    if i == 1:\n",
    "        data_droped_na = data.replace('?', np.NaN).dropna()\n",
    "        X_drop_na = data_droped_na.iloc[:,:-1]\n",
    "        y_drop_na = data_droped_na.iloc[:,-1].apply(lambda x: 0 if x =='>50K' else 1)\n",
    "        for estimator in tqdm([RandomForestClassifier(), GradientBoostingClassifier()]):\n",
    "            for numeric_scaler in [MinMaxScaler(), StandardScaler()]:\n",
    "                preprocessor = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        (\"num\", numeric_scaler, numeric_features),\n",
    "                        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "                    ]\n",
    "                )\n",
    "                clf = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor), (\"classifier\", estimator)]\n",
    "                )\n",
    "                acc = cross_val_score(clf, X_drop_na, y_drop_na, scoring='accuracy', n_jobs=-1).mean()\n",
    "                f1 = cross_val_score(clf, X_drop_na, y_drop_na, scoring='f1', n_jobs=-1).mean()\n",
    "                test_for_res = f'{estimator}, {numeric_scaler}, {categorical_transformer}, NaN dropped : accuracy - {acc}, f1 - {f1}'\n",
    "                print(test_for_res)\n",
    "    if i == 2:\n",
    "        for estimator in tqdm([RandomForestClassifier(), GradientBoostingClassifier()]):\n",
    "            for numeric_scaler in [MinMaxScaler(), StandardScaler()]:\n",
    "                preprocessor = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        (\"num\", numeric_scaler, numeric_features),\n",
    "                        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "                    ]\n",
    "                )\n",
    "                clf = Pipeline(\n",
    "                    steps=[(\"preprocessor\", preprocessor), (\"classifier\", estimator)]\n",
    "                )\n",
    "                acc = cross_val_score(clf, X, y, scoring='accuracy', n_jobs=-1).mean()\n",
    "                f1 = cross_val_score(clf, X, y, scoring='f1', n_jobs=-1).mean()\n",
    "                test_for_res = f'{estimator}, {numeric_scaler}, {categorical_transformer}, no change data : accuracy - {acc}, f1 - {f1}'\n",
    "                print(test_for_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат: \n",
    "GradientBoostingClassifier(), StandardScaler(), OneHotEncoder(handle_unknown='ignore'), no change data : \n",
    "\n",
    "**accuracy - 0.8675935946741558, f1 - 0.9160258070962349**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
